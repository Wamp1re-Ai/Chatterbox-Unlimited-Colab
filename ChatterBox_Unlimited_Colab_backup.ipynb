{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üé§ ChatterBox Unlimited - Colab Edition\n",
    "\n",
    "Welcome to **ChatterBox Unlimited**! This notebook provides a powerful Gradio interface for ResembleAI's state-of-the-art ChatterBox TTS model.\n",
    "\n",
    "## ‚ú® Features\n",
    "- üéØ **Zero-shot TTS**: Generate speech from any text\n",
    "- üé≠ **Voice Cloning**: Clone voices from audio samples\n",
    "- üé® **Emotion Control**: Adjust expressiveness\n",
    "- üöÄ **GPU Acceleration**: Fast generation with Colab's GPUs\n",
    "- üåê **Web Interface**: Beautiful Gradio UI\n",
    "\n",
    "## üöÄ Instructions\n",
    "1. **Enable GPU**: Go to Runtime ‚Üí Change runtime type ‚Üí GPU\n",
    "2. **Run all cells** below in order\n",
    "3. **Access the interface** through the Gradio link\n",
    "4. **Start generating speech**!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_header"
   },
   "source": [
    "## üì¶ Step 1: Install Dependencies\n",
    "\n",
    "This will install all required packages including PyTorch with CUDA support and ChatterBox TTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# CRITICAL FIX for PyTorch/TorchVision compatibility issues\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Force clean Python import cache to avoid circular imports\n",
    "print(\"üßπ Clearing Python import cache...\")\n",
    "for module in list(sys.modules.keys()):\n",
    "    if 'torch' in module or 'vision' in module or 'numpy' in module:\n",
    "        try:\n",
    "            del sys.modules[module]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# Install UV package manager for faster installations\n",
    "!pip install uv\n",
    "\n",
    "# CRITICAL: Complete PyTorch ecosystem cleanup\n",
    "print(\"üßπ Thorough PyTorch cleanup...\")\n",
    "!pip uninstall torch torchvision torchaudio -y --quiet\n",
    "try:\n",
    "    !uv pip uninstall torch torchvision torchaudio -y --quiet\n",
    "except:\n",
    "    pass\n",
    "!pip uninstall torch torchvision torchaudio -y --quiet  # Double cleanup\n",
    "\n",
    "# Clear any cached installations\n",
    "!rm -rf /usr/local/lib/python3.*/dist-packages/torch*\n",
    "!rm -rf ~/.cache/pip/wheels/*torch*\n",
    "!rm -rf ~/.cache/pip/http/*torch*\n",
    "\n",
    "# Get CUDA version and install compatible PyTorch ecosystem\n",
    "print(\"üîç Detecting CUDA version...\")\n",
    "try:\n",
    "    cuda_version = !nvidia-smi --query-gpu=driver_version --format=csv,noheader,nounits\n",
    "    print(f\"   CUDA Driver detected\")\n",
    "    # Use CUDA 12.1 compatible versions for better stability\n",
    "    torch_index = \"https://download.pytorch.org/whl/cu121\"\n",
    "    torch_version = \"2.3.1\"\n",
    "    torchvision_version = \"0.18.1\"\n",
    "    torchaudio_version = \"2.3.1\"\n",
    "except:\n",
    "    print(\"   No CUDA detected, using CPU versions\")\n",
    "    torch_index = \"https://download.pytorch.org/whl/cpu\"\n",
    "    torch_version = \"2.3.1\"\n",
    "    torchvision_version = \"0.18.1\"\n",
    "    torchaudio_version = \"2.3.1\"\n",
    "\n",
    "# Install PyTorch ecosystem with compatible versions in correct order\n",
    "print(f'üîß Installing PyTorch {torch_version} (Step 1/3)...')\n",
    "!pip install torch=={torch_version} --index-url {torch_index}\n",
    "\n",
    "print(f'üîß Installing TorchVision {torchvision_version} (Step 2/3)...')\n",
    "!pip install torchvision=={torchvision_version} --index-url {torch_index}\n",
    "\n",
    "print(f'üîß Installing TorchAudio {torchaudio_version} (Step 3/3)...')\n",
    "!pip install torchaudio=={torchaudio_version} --index-url {torch_index}\n",
    "\n",
    "# Restart Python kernel to clear any import conflicts\n",
    "print(\"üîÑ Clearing import cache after PyTorch installation...\")\n",
    "import importlib\n",
    "import sys\n",
    "for module in list(sys.modules.keys()):\n",
    "    if 'torch' in module:\n",
    "        try:\n",
    "            del sys.modules[module]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# Install compatible numpy version (avoid reload issues)\n",
    "print(\"üìä Installing NumPy...\")\n",
    "!pip install \"numpy>=1.24.0,<2.0.0\" --force-reinstall\n",
    "\n",
    "# Install transformers with proper version that includes is_quanto_available\n",
    "print(\"ü§ñ Installing Transformers with proper version...\")\n",
    "!pip install \"transformers>=4.46.0\" \"accelerate>=0.21.0\" \"safetensors>=0.4.0\"\n",
    "\n",
    "# Install other ML dependencies with compatible versions\n",
    "print(\"üß† Installing ML dependencies...\")\n",
    "!pip install \"diffusers>=0.25.0\" \"omegaconf>=2.3.0\"\n",
    "\n",
    "# Install audio processing dependencies\n",
    "print(\"üéµ Installing audio processing libraries...\")\n",
    "!pip install soundfile librosa resampy\n",
    "\n",
    "# Install Gradio for UI\n",
    "print(\"üåê Installing Gradio...\")\n",
    "!pip install \"gradio>=4.0.0\"\n",
    "\n",
    "# Install ResembleAI specific dependencies\n",
    "print(\"üé§ Installing ResembleAI dependencies...\")\n",
    "!pip install conformer resemble-perth s3tokenizer\n",
    "\n",
    "# Install ChatterBox TTS (try multiple methods)\n",
    "print(\"üéØ Installing ChatterBox TTS...\")\n",
    "import subprocess\n",
    "try:\n",
    "    result = subprocess.run(['pip', 'install', 'chatterbox-tts'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ ChatterBox TTS installed from PyPI\")\n",
    "    else:\n",
    "        raise Exception(\"PyPI install failed\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è PyPI installation failed, trying GitHub...\")\n",
    "    !pip install git+https://github.com/resemble-ai/chatterbox.git\n",
    "    print(\"‚úÖ ChatterBox TTS installed from GitHub\")\n",
    "\n",
    "print(\"\\nüéâ Installation complete! Now testing compatibility...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test_header"
   },
   "source": [
    "## üß™ Step 2: Test Installation\n",
    "\n",
    "This cell tests all dependencies and compatibility to ensure the circular import issue is resolved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_installation"
   },
   "outputs": [],
   "source": [
    "# Test installation with proper error handling\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "def safe_import_test(module_name, test_func=None):\n",
    "    \"\"\"Safely test module import with optional functionality test\"\"\"\n",
    "    try:\n",
    "        # Clear any cached imports first\n",
    "        if module_name in sys.modules:\n",
    "            del sys.modules[module_name]\n",
    "        \n",
    "        module = importlib.import_module(module_name)\n",
    "        version = getattr(module, '__version__', 'unknown')\n",
    "        \n",
    "        if test_func:\n",
    "            test_func(module)\n",
    "        \n",
    "        print(f'‚úÖ {module_name}: {version}')\n",
    "        return True, module\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå {module_name}: {e}')\n",
    "        return False, None\n",
    "\n",
    "print(\"üîç Testing all dependencies...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_good = True\n",
    "\n",
    "# Test PyTorch\n",
    "def test_torch(torch_module):\n",
    "    # Test basic tensor operations\n",
    "    x = torch_module.tensor([1.0, 2.0, 3.0])\n",
    "    y = x * 2\n",
    "    assert y.sum().item() == 12.0\n",
    "\n",
    "success, torch = safe_import_test(\"torch\", test_torch)\n",
    "all_good &= success\n",
    "\n",
    "if success:\n",
    "    print(f'   üéÆ CUDA available: {torch.cuda.is_available()}')\n",
    "    if torch.cuda.is_available():\n",
    "        print(f'   üì± GPU: {torch.cuda.get_device_name(0)}')\n",
    "        print(f'   üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n",
    "        print(f'   üîß CUDA Version: {torch.version.cuda}')\n",
    "\n",
    "# Test TorchVision with specific compatibility check\n",
    "def test_torchvision(tv_module):\n",
    "    # Test the problematic NMS operator that was causing circular imports\n",
    "    import torch\n",
    "    try:\n",
    "        boxes = torch.tensor([[0, 0, 1, 1], [0.5, 0.5, 1.5, 1.5]], dtype=torch.float32)\n",
    "        scores = torch.tensor([0.9, 0.8], dtype=torch.float32)\n",
    "        keep = tv_module.ops.nms(boxes, scores, 0.5)\n",
    "        print(\"   üß™ NMS operator test: PASSED\")\n",
    "    except Exception as e:\n",
    "        print(f'   ‚ö†Ô∏è NMS test failed but torchvision loaded: {e}')\n",
    "        # Test basic transforms instead\n",
    "        transform = tv_module.transforms.ToTensor()\n",
    "        print(\"   üß™ Basic transforms test: PASSED\")\n",
    "\n",
    "success, torchvision = safe_import_test(\"torchvision\", test_torchvision)\n",
    "if not success:\n",
    "    # Try without the test function if it fails\n",
    "    success, torchvision = safe_import_test(\"torchvision\")\n",
    "all_good &= success\n",
    "\n",
    "# Test Transformers with the specific function that was failing\n",
    "def test_transformers(tf_module):\n",
    "    from transformers.utils import is_quanto_available\n",
    "    print(\"   üîß is_quanto_available function: FOUND\")\n",
    "\n",
    "success, transformers = safe_import_test(\"transformers\", test_transformers)\n",
    "all_good &= success\n",
    "\n",
    "# Test other critical dependencies\n",
    "for module in [\"numpy\", \"gradio\", \"soundfile\", \"librosa\"]:\n",
    "    success, _ = safe_import_test(module)\n",
    "    all_good &= success\n",
    "\n",
    "# Test ChatterBox TTS\n",
    "def test_chatterbox(cb_module):\n",
    "    # Just test that we can access the main class\n",
    "    tts_class = getattr(cb_module.tts, 'ChatterboxTTS')\n",
    "    print(\"   üé§ ChatterboxTTS class: ACCESSIBLE\")\n",
    "\n",
    "success, chatterbox = safe_import_test(\"chatterbox\", test_chatterbox)\n",
    "all_good &= success\n",
    "\n",
    "print(\"=\" * 60)\n",
    "if all_good:\n",
    "    print(\"üéâ ALL TESTS PASSED! No circular import issues detected.\")\n",
    "    print(\"üöÄ You can proceed to Step 3.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Some tests failed. Recommended actions:\")\n",
    "    print(\"1. üîÑ Runtime ‚Üí Restart Runtime\")\n",
    "    print(\"2. üîÑ Re-run Step 1\")\n",
    "    print(\"3. üìß If issues persist, check your Colab runtime type (should be GPU)\")\n",
    "\n",
    "print(f'\\nüìä Python version: {sys.version}')\n",
    "print(f'üîç Total modules loaded: {len(sys.modules)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download_header"
   },
   "source": [
    "## üì• Step 3: Download Repository\n",
    "\n",
    "Clone the ChatterBox Unlimited repository with the Gradio interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_repo"
   },
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/Wamp1re-Ai/Chatterbox-Unlimited-Colab.git\n",
    "%cd Chatterbox-Unlimited-Colab\n",
    "\n",
    "# List files\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "launch_header"
   },
   "source": [
    "## üöÄ Step 4: Launch ChatterBox TTS Interface\n",
    "\n",
    "This will start the Gradio web interface. The model will automatically download (~5GB) on first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "launch_interface"
   },
   "outputs": [],
   "source": [
    "# Launch the ChatterBox TTS interface\n",
    "!python main.py --share --port 7860\n",
    "\n",
    "# Note: The interface will be available at the Gradio public link\n",
    "# Look for the line that says \"Running on public URL: https://xxxxx.gradio.live\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usage_instructions"
   },
   "source": [
    "## üéØ How to Use\n",
    "\n",
    "Once the interface is running:\n",
    "\n",
    "### Basic Text-to-Speech\n",
    "1. **Load Model**: Click \"Load ChatterBox TTS Model\" (first time may take a few minutes)\n",
    "2. **Enter Text**: Type your text in the input box\n",
    "3. **Adjust Settings**:\n",
    "   - **Exaggeration**: 0.0-1.0 (emotion intensity)\n",
    "   - **CFG Weight**: 0.0-1.0 (speech pacing)\n",
    "4. **Generate**: Click \"üé§ Generate Speech\"\n",
    "\n",
    "### Voice Cloning\n",
    "1. **Upload Reference Audio**: 3-10 seconds of clear speech\n",
    "2. **Enter Text**: What you want the cloned voice to say\n",
    "3. **Generate**: The output will mimic the reference voice\n",
    "\n",
    "### Tips for Best Results\n",
    "- **General Use**: Default settings (0.5, 0.5) work well\n",
    "- **Expressive Speech**: Lower CFG (~0.3) + higher exaggeration (~0.7+)\n",
    "- **Voice Cloning**: Use clear, high-quality reference audio\n",
    "- **GPU Acceleration**: Colab's GPU will make generation much faster!\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Notes\n",
    "- Generated audio includes watermarking for responsible AI use\n",
    "- First model load downloads ~5GB of weights\n",
    "- Colab session will timeout after inactivity\n",
    "- For extended use, consider Colab Pro for longer sessions\n",
    "\n",
    "## üîß Troubleshooting\n",
    "\n",
    "### Fixed Issues in This Version\n",
    "\n",
    "**‚úÖ FIXED: `partially initialized module 'torchvision' has no attribute 'extension'`**\n",
    "- **Root Cause**: Version mismatch between PyTorch and TorchVision\n",
    "- **Solution**: Complete cleanup + compatible version installation + import cache clearing\n",
    "- **Prevention**: Uses compatible PyTorch 2.3.1 + TorchVision 0.18.1 + CUDA 12.1\n",
    "\n",
    "**‚úÖ FIXED: `cannot import name 'is_quanto_available' from 'transformers.utils'`**\n",
    "- **Root Cause**: Outdated transformers version\n",
    "- **Solution**: Updated to transformers>=4.46.0\n",
    "\n",
    "**‚úÖ FIXED: NumPy reload warnings**\n",
    "- **Root Cause**: Multiple NumPy imports causing conflicts\n",
    "- **Solution**: Force reinstall with compatible version + import cache clearing\n",
    "\n",
    "### Common Issues and Solutions\n",
    "\n",
    "**‚ùå ChatterBox TTS import fails**\n",
    "- **Solution**: The notebook tries both PyPI and GitHub installation\n",
    "- **Manual fix**: `!pip install git+https://github.com/resemble-ai/chatterbox.git`\n",
    "\n",
    "**‚ö†Ô∏è Slow generation**\n",
    "- **Check**: Make sure GPU is enabled (Runtime ‚Üí Change runtime type ‚Üí GPU)\n",
    "- **Verify**: Step 2 should show your GPU name\n",
    "\n",
    "**üîÑ General troubleshooting steps:**\n",
    "1. Restart runtime: Runtime ‚Üí Restart Runtime\n",
    "2. Re-run all cells from Step 1\n",
    "3. If Step 2 shows issues, repeat steps 1-2\n",
    "4. Check that GPU is enabled in runtime settings\n",
    "\n",
    "## üîó Links\n",
    "- [GitHub Repository](https://github.com/Wamp1re-Ai/Chatterbox-Unlimited-Colab)\n",
    "- [ResembleAI ChatterBox](https://github.com/resemble-ai/chatterbox)\n",
    "- [Hugging Face Model](https://huggingface.co/ResembleAI/chatterbox)\n",
    "\n",
    "**Enjoy creating amazing speech with ChatterBox Unlimited! üéâ**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}