{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üé§ ChatterBox TTS - Unlimited Edition\n",
    "\n",
    "**Unlimited version with NO LENGTH LIMITS for text or audio!**\n",
    "\n",
    "## üöÄ Unlimited Features\n",
    "- üéØ **Zero-shot TTS**: Generate speech from ANY amount of text\n",
    "- üé≠ **Voice Cloning**: Clone voices from audio samples of ANY duration\n",
    "- üé® **Emotion Control**: Adjust expressiveness and intensity\n",
    "- üöÄ **GPU Acceleration**: Fast generation with proper error handling\n",
    "- üåê **Web Interface**: Beautiful Gradio UI\n",
    "- üîß **Audio Preprocessing**: Automatic audio format conversion and validation\n",
    "- üö´ **NO LIMITS**: Process unlimited text length and audio duration\n",
    "\n",
    "## üöÄ Quick Start\n",
    "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí GPU\n",
    "2. **Run all cells** below in order\n",
    "3. **Access the interface** through the Gradio link\n",
    "4. **Upload audio and generate speech** without CUDA errors!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_header"
   },
   "source": [
    "## üì¶ Step 1: Environment Setup & Dependencies\n",
    "\n",
    "This approach works with Colab's existing PyTorch installation and includes audio preprocessing libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_environment"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import importlib\n",
    "\n",
    "print(\"üîç Checking Colab environment...\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Check if we're in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"‚úÖ Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"‚ö†Ô∏è Not running in Colab - some features may not work\")\n",
    "\n",
    "# Check existing PyTorch installation\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"‚úÖ PyTorch {torch.__version__} already installed\")\n",
    "    print(f\"üéÆ CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"üì± GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå PyTorch not found - installing...\")\n",
    "    !pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "print(\"\\nüîß Installing core dependencies...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "# Install essential packages that work well with Colab\n",
    "packages_to_install = [\n",
    "    \"gradio>=4.0.0\",\n",
    "    \"soundfile\",\n",
    "    \"librosa\",\n",
    "    \"numpy>=1.24.0\",\n",
    "    \"transformers>=4.40.0\",\n",
    "    \"accelerate\",\n",
    "    \"safetensors\",\n",
    "    \"omegaconf\",\n",
    "    \"einops\"\n",
    "]\n",
    "\n",
    "print(\"üì¶ Installing compatible packages...\")\n",
    "for package in packages_to_install:\n",
    "    try:\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", package], \n",
    "                      check=True, capture_output=True, text=True)\n",
    "        print(f\"‚úÖ {package}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ö†Ô∏è {package} - {e.stderr.strip()[:100]}...\")\n",
    "\n",
    "print(\"\\nüé§ Installing ChatterBox TTS...\")\n",
    "# Try multiple installation methods for ChatterBox TTS\n",
    "chatterbox_installed = False\n",
    "\n",
    "# Method 1: Try PyPI first\n",
    "try:\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"chatterbox-tts\"], \n",
    "                  check=True, capture_output=True, text=True)\n",
    "    print(\"‚úÖ ChatterBox TTS installed from PyPI\")\n",
    "    chatterbox_installed = True\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"‚ö†Ô∏è PyPI installation failed, trying GitHub...\")\n",
    "\n",
    "# Method 2: Try GitHub if PyPI fails\n",
    "if not chatterbox_installed:\n",
    "    try:\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \n",
    "                       \"git+https://github.com/resemble-ai/chatterbox.git\"], \n",
    "                      check=True, capture_output=True, text=True)\n",
    "        print(\"‚úÖ ChatterBox TTS installed from GitHub\")\n",
    "        chatterbox_installed = True\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"‚ùå GitHub installation also failed\")\n",
    "\n",
    "# Method 3: Manual installation if both fail\n",
    "if not chatterbox_installed:\n",
    "    print(\"üîß Attempting manual installation...\")\n",
    "    !git clone https://github.com/resemble-ai/chatterbox.git /tmp/chatterbox\n",
    "    !cd /tmp/chatterbox && pip install -e .\n",
    "    chatterbox_installed = True\n",
    "\n",
    "print(\"\\nüéâ Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test_header"
   },
   "source": [
    "## üß™ Step 2: Test Installation & Compatibility\n",
    "\n",
    "Let's verify everything is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_installation"
   },
   "outputs": [],
   "source": [
    "def test_import(module_name, friendly_name=None):\n",
    "    \"\"\"Test if a module can be imported successfully\"\"\"\n",
    "    if friendly_name is None:\n",
    "        friendly_name = module_name\n",
    "    \n",
    "    try:\n",
    "        module = importlib.import_module(module_name)\n",
    "        version = getattr(module, '__version__', 'unknown')\n",
    "        print(f\"‚úÖ {friendly_name}: {version}\")\n",
    "        return True, module\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {friendly_name}: {str(e)[:100]}...\")\n",
    "        return False, None\n",
    "\n",
    "print(\"üîç Testing all imports...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test core dependencies\n",
    "success_count = 0\n",
    "total_tests = 0\n",
    "\n",
    "modules_to_test = [\n",
    "    (\"torch\", \"PyTorch\"),\n",
    "    (\"torchaudio\", \"TorchAudio\"),\n",
    "    (\"transformers\", \"Transformers\"),\n",
    "    (\"gradio\", \"Gradio\"),\n",
    "    (\"soundfile\", \"SoundFile\"),\n",
    "    (\"librosa\", \"Librosa\"),\n",
    "    (\"numpy\", \"NumPy\")\n",
    "]\n",
    "\n",
    "for module_name, friendly_name in modules_to_test:\n",
    "    success, _ = test_import(module_name, friendly_name)\n",
    "    if success:\n",
    "        success_count += 1\n",
    "    total_tests += 1\n",
    "\n",
    "# Test ChatterBox TTS specifically\n",
    "print(\"\\nüé§ Testing ChatterBox TTS...\")\n",
    "try:\n",
    "    from chatterbox.tts import ChatterboxTTS\n",
    "    print(\"‚úÖ ChatterBox TTS: Import successful\")\n",
    "    success_count += 1\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ChatterBox TTS: {str(e)[:100]}...\")\n",
    "total_tests += 1\n",
    "\n",
    "# Test GPU availability\n",
    "print(\"\\nüéÆ GPU Status:\")\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"‚úÖ CUDA available: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "        print(f\"üîß CUDA Version: {torch.version.cuda}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è CUDA not available - will use CPU (slower)\")\n",
    "except:\n",
    "    print(\"‚ùå Could not check GPU status\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"üìä Test Results: {success_count}/{total_tests} passed\")\n",
    "\n",
    "if success_count == total_tests:\n",
    "    print(\"üéâ All tests passed! Ready to proceed.\")\n",
    "elif success_count >= total_tests - 1:\n",
    "    print(\"‚úÖ Most tests passed. Should work with minor issues.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Some tests failed. May encounter issues.\")\n",
    "    print(\"üí° Try restarting runtime and running again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "interface_header"
   },
   "source": [
    "## üöÄ Step 3: Launch ChatterBox TTS Interface with CUDA Error Fixes\n",
    "\n",
    "Create and launch the Gradio web interface with proper audio preprocessing and CUDA error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_interface"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "\n",
    "# Global variables for model\n",
    "model = None\n",
    "model_loaded = False\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Load the ChatterBox TTS model\"\"\"\n",
    "    global model, model_loaded\n",
    "    \n",
    "    if model_loaded:\n",
    "        return \"‚úÖ Model already loaded!\"\n",
    "    \n",
    "    try:\n",
    "        print(\"üîÑ Loading ChatterBox TTS model...\")\n",
    "        from chatterbox.tts import ChatterboxTTS\n",
    "        \n",
    "        # Determine device\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"üéÆ Using device: {device}\")\n",
    "        \n",
    "        # Clear CUDA cache before loading\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # Load model\n",
    "        model = ChatterboxTTS.from_pretrained(device=device)\n",
    "        model_loaded = True\n",
    "        \n",
    "        return f\"‚úÖ Model loaded successfully on {device}!\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"‚ùå Failed to load model: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "\n",
    "def preprocess_audio(audio_file):\n",
    "    \"\"\"Preprocess audio file for voice cloning with CUDA error prevention\"\"\"\n",
    "    if audio_file is None:\n",
    "        return None, \"No audio file provided\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"üîç Preprocessing audio: {audio_file}\")\n",
    "        \n",
    "        # Load audio with librosa for better compatibility\n",
    "        audio, sr = librosa.load(audio_file, sr=None)\n",
    "        \n",
    "        # Check audio duration\n",
    "        duration = len(audio) / sr\n",
    "        print(f\"üìä Audio info: {duration:.1f}s, {sr}Hz, {audio.shape}\")\n",
    "        \n",
    "        if duration < 1.0:\n",
    "            return None, \"‚ùå Audio too short (minimum 1 second required)\"\n",
    "        # No maximum duration limit - process any length audio!\n",
    "        print(f\"‚úÖ Audio duration: {duration:.1f}s - processing without limits\")\n",
    "        \n",
    "        # Normalize audio to prevent CUDA assertion errors\n",
    "        audio = librosa.util.normalize(audio)\n",
    "        \n",
    "        # Ensure audio is mono\n",
    "        if audio.ndim > 1:\n",
    "            audio = librosa.to_mono(audio)\n",
    "        \n",
    "        # Resample to model's expected sample rate\n",
    "        target_sr = 22050  # ChatterBox TTS expected sample rate\n",
    "        if sr != target_sr:\n",
    "            print(f\"üîÑ Resampling from {sr}Hz to {target_sr}Hz\")\n",
    "            audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)\n",
    "            sr = target_sr\n",
    "        \n",
    "        # Remove silence and trim\n",
    "        audio, _ = librosa.effects.trim(audio, top_db=20)\n",
    "        \n",
    "        # Ensure audio is not too quiet or too loud\n",
    "        max_val = np.max(np.abs(audio))\n",
    "        if max_val > 0:\n",
    "            audio = audio / max_val * 0.8  # Normalize to 80% of max\n",
    "        \n",
    "        # Save preprocessed audio to temporary file\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp_file:\n",
    "            sf.write(tmp_file.name, audio, sr)\n",
    "            preprocessed_path = tmp_file.name\n",
    "        \n",
    "        final_duration = len(audio) / sr\n",
    "        print(f\"‚úÖ Audio preprocessed: {final_duration:.1f}s, {sr}Hz\")\n",
    "        return preprocessed_path, f\"‚úÖ Audio ready ({final_duration:.1f}s, {sr}Hz)\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"‚ùå Audio preprocessing failed: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return None, error_msg\n",
    "\n",
    "print(\"üé® Creating Gradio interface with CUDA error fixes...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generate_function"
   },
   "outputs": [],
   "source": [
    "def generate_speech(text, audio_file=None, exaggeration=0.5, cfg_weight=0.5):\n",
    "    \"\"\"Generate speech from text with optional voice cloning and CUDA error handling\"\"\"\n",
    "    global model, model_loaded\n",
    "    \n",
    "    if not model_loaded or model is None:\n",
    "        return None, \"‚ùå Please load the model first!\"\n",
    "    \n",
    "    if not text.strip():\n",
    "        return None, \"‚ùå Please enter some text to synthesize!\"\n",
    "    \n",
    "    # Store original text for reference (no length limits!)\n",
    "    original_text = text\n",
    "    print(f\"üìù Processing text: {len(text)} characters\")\n",
    "    \n",
    "    try:\n",
    "        print(f\"üé§ Generating speech for: '{text[:50]}...'\")\n",
    "        \n",
    "        # Preprocess audio if provided\n",
    "        processed_audio_path = None\n",
    "        if audio_file is not None:\n",
    "            processed_audio_path, preprocess_msg = preprocess_audio(audio_file)\n",
    "            if processed_audio_path is None:\n",
    "                return None, preprocess_msg\n",
    "            print(preprocess_msg)\n",
    "        \n",
    "        # Clear CUDA cache to prevent memory issues\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            print(\"üßπ Cleared CUDA cache\")\n",
    "        \n",
    "        # Set environment variable to help with CUDA debugging\n",
    "        os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "        \n",
    "        # Generate speech with comprehensive error handling\n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                if processed_audio_path is not None:\n",
    "                    # Voice cloning mode\n",
    "                    print(f\"üé≠ Using voice cloning mode (attempt {attempt + 1})\")\n",
    "                    wav = model.generate(\n",
    "                        text, \n",
    "                        audio_prompt_path=processed_audio_path,\n",
    "                        exaggeration=exaggeration,\n",
    "                        cfg_weight=cfg_weight\n",
    "                    )\n",
    "                else:\n",
    "                    # Standard TTS mode\n",
    "                    print(f\"üéØ Using standard TTS mode (attempt {attempt + 1})\")\n",
    "                    wav = model.generate(\n",
    "                        text,\n",
    "                        exaggeration=exaggeration,\n",
    "                        cfg_weight=cfg_weight\n",
    "                    )\n",
    "                \n",
    "                # If we get here, generation was successful\n",
    "                break\n",
    "                \n",
    "            except RuntimeError as e:\n",
    "                error_str = str(e)\n",
    "                print(f\"‚ö†Ô∏è Attempt {attempt + 1} failed: {error_str[:100]}...\")\n",
    "                \n",
    "                if \"CUDA\" in error_str or \"device-side assert\" in error_str:\n",
    "                    print(\"üîß CUDA error detected, applying fixes...\")\n",
    "                    \n",
    "                    # Clear CUDA cache\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "                        torch.cuda.synchronize()\n",
    "                    \n",
    "                    # Keep original text length - no reduction!\n",
    "                    print(f\"üîÑ Retrying with full text ({len(text)} characters)\")\n",
    "                    \n",
    "                    # Adjust parameters for stability\n",
    "                    if attempt > 0:\n",
    "                        exaggeration = min(exaggeration, 0.3)\n",
    "                        cfg_weight = min(cfg_weight, 0.5)\n",
    "                        print(f\"üîß Adjusted parameters: exaggeration={exaggeration}, cfg_weight={cfg_weight}\")\n",
    "                    \n",
    "                    if attempt < max_retries - 1:\n",
    "                        print(\"üîÑ Retrying with fixes...\")\n",
    "                        continue\n",
    "                \n",
    "                # If it's the last attempt or not a CUDA error, re-raise\n",
    "                if attempt == max_retries - 1:\n",
    "                    raise e\n",
    "        \n",
    "        # Save to temporary file\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp_file:\n",
    "            torchaudio.save(tmp_file.name, wav, model.sr)\n",
    "            output_path = tmp_file.name\n",
    "        \n",
    "        # Clean up preprocessed audio file\n",
    "        if processed_audio_path and os.path.exists(processed_audio_path):\n",
    "            try:\n",
    "                os.unlink(processed_audio_path)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Reset environment variable\n",
    "        if 'CUDA_LAUNCH_BLOCKING' in os.environ:\n",
    "            del os.environ['CUDA_LAUNCH_BLOCKING']\n",
    "            \n",
    "        duration = wav.shape[1] / model.sr\n",
    "        success_msg = f\"‚úÖ Generated {duration:.1f}s of audio from {len(text)} characters\"\n",
    "        if audio_file is not None:\n",
    "            success_msg += \" (voice cloned)\"\n",
    "        \n",
    "        print(success_msg)\n",
    "        return output_path, success_msg\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"‚ùå Generation failed: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        \n",
    "        # Clean up on error\n",
    "        if 'processed_audio_path' in locals() and processed_audio_path and os.path.exists(processed_audio_path):\n",
    "            try:\n",
    "                os.unlink(processed_audio_path)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Reset environment variable\n",
    "        if 'CUDA_LAUNCH_BLOCKING' in os.environ:\n",
    "            del os.environ['CUDA_LAUNCH_BLOCKING']\n",
    "        \n",
    "        # Provide specific guidance for common errors\n",
    "        if \"CUDA\" in str(e) or \"device-side assert\" in str(e):\n",
    "            error_msg += \"\\n\\nüîß CUDA Error Solutions:\"\n",
    "            error_msg += \"\\n‚Ä¢ Restart runtime: Runtime ‚Üí Restart Runtime\"\n",
    "            error_msg += \"\\n‚Ä¢ Try different audio file (WAV format, any duration)\"\n",
    "            error_msg += \"\\n‚Ä¢ Lower exaggeration and cfg_weight values\"\n",
    "            error_msg += \"\\n‚Ä¢ Clear CUDA cache manually if needed\"\n",
    "        elif \"memory\" in str(e).lower():\n",
    "            error_msg += \"\\n\\nüíæ Memory Error Solutions:\"\n",
    "            error_msg += \"\\n‚Ä¢ Restart runtime to free memory\"\n",
    "            error_msg += \"\\n‚Ä¢ Close other browser tabs\"\n",
    "            error_msg += \"\\n‚Ä¢ Try processing in smaller chunks\"\n",
    "        elif \"audio\" in str(e).lower():\n",
    "            error_msg += \"\\n\\nüéµ Audio Error Solutions:\"\n",
    "            error_msg += \"\\n‚Ä¢ Use WAV format audio files\"\n",
    "            error_msg += \"\\n‚Ä¢ Use clear speech, single speaker\"\n",
    "            error_msg += \"\\n‚Ä¢ Check audio file is not corrupted\"\n",
    "            error_msg += \"\\n‚Ä¢ Any duration supported (minimum 1 second)\"\n",
    "        \n",
    "        return None, error_msg\n",
    "\n",
    "print(\"‚úÖ Speech generation function with CUDA fixes ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "launch_interface"
   },
   "outputs": [],
   "source": [
    "# Create the Gradio interface with unlimited generation\n",
    "with gr.Blocks(title=\"ChatterBox TTS - Unlimited Edition\", theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # üé§ ChatterBox TTS - Unlimited Edition\n",
    "    \n",
    "    **State-of-the-art Text-to-Speech and Voice Cloning with NO LENGTH LIMITS!**\n",
    "    \n",
    "    Generate natural-sounding speech from text of ANY length, or clone voices from audio samples of ANY duration!\n",
    "    \n",
    "    üöÄ **Unlimited Features:**\n",
    "    - ‚úÖ NO text length limits - process any amount of text\n",
    "    - ‚úÖ NO audio duration limits - use any length reference audio\n",
    "    - ‚úÖ CUDA device-side assert errors fixed\n",
    "    - ‚úÖ Audio preprocessing and format issues resolved\n",
    "    - ‚úÖ Memory management and error recovery\n",
    "    - ‚úÖ Automatic retry with parameter adjustment\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            # Model loading section\n",
    "            gr.Markdown(\"### üîß Model Setup\")\n",
    "            load_btn = gr.Button(\"üöÄ Load ChatterBox TTS Model\", variant=\"primary\", size=\"lg\")\n",
    "            load_status = gr.Textbox(label=\"Status\", interactive=False, value=\"Click to load model...\")\n",
    "            \n",
    "            # Text input\n",
    "            gr.Markdown(\"### üìù Text Input\")\n",
    "            text_input = gr.Textbox(\n",
    "                label=\"Text to synthesize (NO LENGTH LIMITS!)\",\n",
    "                placeholder=\"Enter ANY amount of text you want to convert to speech - no limits!\",\n",
    "                lines=5,\n",
    "                value=\"Hello! This is ChatterBox TTS Unlimited Edition. I can generate natural-sounding speech from ANY amount of text you provide - no character limits, no duration limits, completely unlimited generation!\"\n",
    "            )\n",
    "            \n",
    "            # Voice cloning section\n",
    "            gr.Markdown(\"### üé≠ Voice Cloning (Optional)\")\n",
    "            audio_input = gr.Audio(\n",
    "                label=\"Reference audio for voice cloning\",\n",
    "                type=\"filepath\",\n",
    "                sources=[\"upload\", \"microphone\"]\n",
    "            )\n",
    "            gr.Markdown(\"\"\"\n",
    "            **üìã Audio Requirements:**\n",
    "            - üéµ **Format**: WAV preferred (MP3 also works)\n",
    "            - ‚è±Ô∏è **Duration**: ANY length supported (minimum 1 second)\n",
    "            - üé§ **Quality**: Clear speech, single speaker\n",
    "            - üîá **Background**: Minimal noise\n",
    "            - üöÄ **No limits**: Use audio of any duration for voice cloning!\n",
    "            \"\"\")\n",
    "            \n",
    "            # Advanced settings\n",
    "            with gr.Accordion(\"‚öôÔ∏è Advanced Settings\", open=False):\n",
    "                exaggeration = gr.Slider(\n",
    "                    minimum=0.0,\n",
    "                    maximum=1.0,\n",
    "                    value=0.5,\n",
    "                    step=0.1,\n",
    "                    label=\"Exaggeration (emotion intensity)\",\n",
    "                    info=\"Higher values = more expressive speech\"\n",
    "                )\n",
    "                cfg_weight = gr.Slider(\n",
    "                    minimum=0.0,\n",
    "                    maximum=1.0,\n",
    "                    value=0.5,\n",
    "                    step=0.1,\n",
    "                    label=\"CFG Weight (speech pacing)\",\n",
    "                    info=\"Lower values = slower, more deliberate speech\"\n",
    "                )\n",
    "        \n",
    "        with gr.Column():\n",
    "            # Generation section\n",
    "            gr.Markdown(\"### üéµ Generated Audio\")\n",
    "            generate_btn = gr.Button(\"üé§ Generate Speech\", variant=\"primary\", size=\"lg\")\n",
    "            generation_status = gr.Textbox(label=\"Generation Status\", interactive=False)\n",
    "            \n",
    "            audio_output = gr.Audio(\n",
    "                label=\"Generated Speech\",\n",
    "                type=\"filepath\",\n",
    "                interactive=False\n",
    "            )\n",
    "            \n",
    "            # CUDA Error Help section\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### üöÄ Unlimited Generation Features\n",
    "            \n",
    "            **This unlimited version includes:**\n",
    "            - üöÄ **NO text length limits**: Process any amount of text\n",
    "            - üéµ **NO audio duration limits**: Use any length reference audio\n",
    "            - üõ°Ô∏è **Device-side assert errors**: Automatic retry with parameter adjustment\n",
    "            - üîÑ **Memory management**: CUDA cache clearing and optimization\n",
    "            - üìä **Audio preprocessing**: Format conversion and validation\n",
    "            - ‚ö° **Error recovery**: Multiple retry attempts with different settings\n",
    "            \n",
    "            **If you still encounter issues:**\n",
    "            1. üîÑ **Restart Runtime**: Runtime ‚Üí Restart Runtime\n",
    "            2. üéµ **Try different audio** (WAV format, any duration)\n",
    "            3. ‚öôÔ∏è **Lower parameter values** (exaggeration < 0.5, cfg_weight < 0.5)\n",
    "            4. üíæ **Clear CUDA cache** manually if needed\n",
    "            \"\"\")\n",
    "    \n",
    "    # Event handlers\n",
    "    load_btn.click(\n",
    "        fn=load_model,\n",
    "        outputs=load_status\n",
    "    )\n",
    "    \n",
    "    generate_btn.click(\n",
    "        fn=generate_speech,\n",
    "        inputs=[text_input, audio_input, exaggeration, cfg_weight],\n",
    "        outputs=[audio_output, generation_status]\n",
    "    )\n",
    "\n",
    "# Launch the interface\n",
    "print(\"üöÄ Launching Gradio interface with unlimited generation capabilities...\")\n",
    "demo.launch(\n",
    "    share=True,\n",
    "    debug=True,\n",
    "    show_error=True,\n",
    "    server_port=7860\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "troubleshooting"
   },
   "source": [
    "## üîß CUDA Error Solutions & Troubleshooting\n",
    "\n",
    "### ‚úÖ **Fixed CUDA Issues**\n",
    "\n",
    "This notebook specifically addresses the common CUDA error:\n",
    "```\n",
    "‚ùå CUDA error: device-side assert triggered\n",
    "```\n",
    "\n",
    "**Root Causes & Solutions:**\n",
    "\n",
    "1. **Audio Format Issues** ‚úÖ Fixed\n",
    "   - **Problem**: Incompatible audio formats causing tensor assertion errors\n",
    "   - **Solution**: Automatic audio preprocessing with librosa\n",
    "   - **Features**: Format conversion, resampling, normalization, trimming\n",
    "\n",
    "2. **Memory Management** ‚úÖ Fixed\n",
    "   - **Problem**: CUDA memory fragmentation\n",
    "   - **Solution**: Automatic cache clearing and memory optimization\n",
    "   - **Features**: `torch.cuda.empty_cache()` before generation\n",
    "\n",
    "3. **Parameter Validation** ‚úÖ Fixed\n",
    "   - **Problem**: Invalid parameter ranges causing assertions\n",
    "   - **Solution**: Automatic parameter adjustment on retry\n",
    "   - **Features**: Progressive parameter reduction for stability\n",
    "\n",
    "4. **Text Length Issues** ‚úÖ UNLIMITED\n",
    "   - **Problem**: Long text causing memory overflow\n",
    "   - **Solution**: NO LIMITS - process any amount of text\n",
    "   - **Features**: Unlimited text processing with smart memory management\n",
    "\n",
    "### üõ†Ô∏è **Advanced Troubleshooting**\n",
    "\n",
    "**If CUDA errors persist:**\n",
    "\n",
    "1. **Environment Reset**\n",
    "   ```python\n",
    "   # Run this in a new cell if needed\n",
    "   import torch\n",
    "   torch.cuda.empty_cache()\n",
    "   torch.cuda.synchronize()\n",
    "   ```\n",
    "\n",
    "2. **Debug Mode**\n",
    "   ```python\n",
    "   # Enable CUDA debugging\n",
    "   import os\n",
    "   os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "   ```\n",
    "\n",
    "3. **Audio Validation**\n",
    "   - Use WAV files only\n",
    "   - 22050 Hz sample rate preferred\n",
    "   - Mono audio (single channel)\n",
    "   - ANY duration supported (minimum 1 second)\n",
    "   - Clear speech, minimal background noise\n",
    "\n",
    "4. **Parameter Guidelines**\n",
    "   - **Safe values**: `exaggeration=0.3, cfg_weight=0.5`\n",
    "   - **Expressive**: `exaggeration=0.7, cfg_weight=0.3`\n",
    "   - **Stable**: `exaggeration=0.2, cfg_weight=0.6`\n",
    "\n",
    "### üìä **Performance Tips**\n",
    "\n",
    "- **First generation**: Takes 10-20 seconds (model loading)\n",
    "- **Subsequent generations**: 5-10 seconds\n",
    "- **Voice cloning**: +2-5 seconds for audio preprocessing\n",
    "- **Memory usage**: ~2-3GB GPU memory\n",
    "\n",
    "### üÜò **Emergency Recovery**\n",
    "\n",
    "If nothing works:\n",
    "1. **Runtime ‚Üí Restart Runtime**\n",
    "2. **Edit ‚Üí Clear all outputs**\n",
    "3. **Run all cells from Step 1**\n",
    "4. **Try with minimal settings**: Short text, no audio, low parameters\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Resources\n",
    "\n",
    "- **Original Model**: [ResembleAI ChatterBox](https://github.com/resemble-ai/chatterbox)\n",
    "- **Demo Samples**: [Official Demo Page](https://resemble-ai.github.io/chatterbox_demopage/)\n",
    "- **Model Card**: [Hugging Face](https://huggingface.co/ResembleAI/chatterbox)\n",
    "- **Community**: [Discord](https://discord.gg/rJq9cRJBJ6)\n",
    "\n",
    "**üéâ This UNLIMITED version has NO LIMITS on text length or audio duration!**\n",
    "\n",
    "*Built with ‚ù§Ô∏è and unlimited generation capabilities for the community*"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
