{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# 🎤 ChatterBox Unlimited - Colab Edition\n",
    "\n",
    "Welcome to **ChatterBox Unlimited**! This notebook provides a powerful Gradio interface for ResembleAI's state-of-the-art ChatterBox TTS model.\n",
    "\n",
    "## ✨ Features\n",
    "- 🎯 **Zero-shot TTS**: Generate speech from any text\n",
    "- 🎭 **Voice Cloning**: Clone voices from audio samples\n",
    "- 🎨 **Emotion Control**: Adjust expressiveness\n",
    "- 🚀 **GPU Acceleration**: Fast generation with Colab's GPUs\n",
    "- 🌐 **Web Interface**: Beautiful Gradio UI\n",
    "\n",
    "## 🚀 Instructions\n",
    "1. **Enable GPU**: Go to Runtime → Change runtime type → GPU\n",
    "2. **Run all cells** below in order\n",
    "3. **Access the interface** through the Gradio link\n",
    "4. **Start generating speech**!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_header"
   },
   "source": [
    "## 📦 Step 1: Install Dependencies\n",
    "\n",
    "This will install all required packages including PyTorch with CUDA support and ChatterBox TTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# CRITICAL FIX for PyTorch/TorchVision circular import issue\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Force clean Python import cache to avoid circular imports\n",
    "print(\"🧹 Clearing Python import cache...\")\n",
    "for module in list(sys.modules.keys()):\n",
    "    if 'torch' in module or 'vision' in module:\n",
    "        del sys.modules[module]\n",
    "\n",
    "# Install UV package manager for faster installations\n",
    "!pip install uv\n",
    "\n",
    "# CRITICAL: Complete PyTorch ecosystem cleanup\n",
    "print(\"🧹 Thorough PyTorch cleanup...\")\n",
    "!pip uninstall torch torchvision torchaudio -y --quiet\n",
    "!uv pip uninstall torch torchvision torchaudio -y --quiet\n",
    "!pip uninstall torch torchvision torchaudio -y --quiet  # Double cleanup\n",
    "\n",
    "# Clear any cached installations\n",
    "!rm -rf /usr/local/lib/python3.*/dist-packages/torch*\n",
    "!rm -rf ~/.cache/pip/wheels/*torch*\n",
    "\n",
    "# Install PyTorch ecosystem with EXACT compatible versions in correct order\n",
    "print(\"🔧 Installing PyTorch ecosystem (Step 1/3)...\")\n",
    "!pip install torch==2.1.0 --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "print(\"🔧 Installing TorchVision (Step 2/3)...\")\n",
    "!pip install torchvision==0.16.0 --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "print(\"🔧 Installing TorchAudio (Step 3/3)...\")\n",
    "!pip install torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Restart Python kernel to clear any import conflicts\n",
    "print(\"🔄 Clearing import cache after PyTorch installation...\")\n",
    "import importlib\n",
    "import sys\n",
    "for module in list(sys.modules.keys()):\n",
    "    if 'torch' in module:\n",
    "        try:\n",
    "            del sys.modules[module]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# Install compatible numpy version\n",
    "print(\"📊 Installing NumPy...\")\n",
    "!pip install \"numpy>=1.21.0,<1.25.0\"\n",
    "\n",
    "# Install transformers with proper version that includes is_quanto_available\n",
    "print(\"🤖 Installing Transformers with proper version...\")\n",
    "!pip install \"transformers>=4.46.0\" \"accelerate>=0.21.0\"\n",
    "\n",
    "# Install other ML dependencies with compatible versions\n",
    "print(\"🧠 Installing ML dependencies...\")\n",
    "!pip install \"diffusers>=0.25.0\" \"omegaconf>=2.3.0\"\n",
    "\n",
    "# Install audio processing dependencies\n",
    "print(\"🎵 Installing audio processing libraries...\")\n",
    "!pip install soundfile librosa resampy\n",
    "\n",
    "# Install Gradio for UI\n",
    "print(\"🌐 Installing Gradio...\")\n",
    "!pip install \"gradio>=4.0.0\"\n",
    "\n",
    "# Install ResembleAI specific dependencies\n",
    "print(\"🎤 Installing ResembleAI dependencies...\")\n",
    "!pip install conformer resemble-perth s3tokenizer\n",
    "\n",
    "# Install ChatterBox TTS (try multiple methods)\n",
    "print(\"🎯 Installing ChatterBox TTS...\")\n",
    "import subprocess\n",
    "try:\n",
    "    result = subprocess.run(['pip', 'install', 'chatterbox-tts'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"✅ ChatterBox TTS installed from PyPI\")\n",
    "    else:\n",
    "        raise Exception(\"PyPI install failed\")\n",
    "except:\n",
    "    print(\"⚠️ PyPI installation failed, trying GitHub...\")\n",
    "    !pip install git+https://github.com/resemble-ai/chatterbox.git\n",
    "    print(\"✅ ChatterBox TTS installed from GitHub\")\n",
    "\n",
    "print(\"\\n🎉 Installation complete! Now testing compatibility...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test_header"
   },
   "source": [
    "## 🧪 Step 2: Test Installation\n",
    "\n",
    "This cell tests all dependencies and compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_installation"
   },
   "outputs": [],
   "source": [
    "# Test installation with proper error handling\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "def safe_import_test(module_name, test_func=None):\n",
    "    \"\"\"Safely test module import with optional functionality test\"\"\"\n",
    "    try:\n",
    "        # Clear any cached imports first\n",
    "        if module_name in sys.modules:\n",
    "            del sys.modules[module_name]\n",
    "        \n",
    "        module = importlib.import_module(module_name)\n",
    "        version = getattr(module, '__version__', 'unknown')\n",
    "        \n",
    "        if test_func:\n",
    "            test_func(module)\n",
    "        \n",
    "        print(f\"✅ {module_name}: {version}\")\n",
    "        return True, module\n",
    "    except Exception as e:\n",
    "        print(f\"❌ {module_name}: {e}\")\n",
    "        return False, None\n",
    "\n",
    "print(\"🔍 Testing all dependencies...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_good = True\n",
    "\n",
    "# Test PyTorch\n",
    "def test_torch(torch_module):\n",
    "    # Test basic tensor operations\n",
    "    x = torch_module.tensor([1.0, 2.0, 3.0])\n",
    "    y = x * 2\n",
    "    assert y.sum().item() == 12.0\n",
    "\n",
    "success, torch = safe_import_test(\"torch\", test_torch)\n",
    "all_good &= success\n",
    "\n",
    "if success:\n",
    "    print(f\"   🎮 CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"   📱 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"   💾 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "        print(f\"   🔧 CUDA Version: {torch.version.cuda}\")\n",
    "\n",
    "# Test TorchVision with specific compatibility check\n",
    "def test_torchvision(tv_module):\n",
    "    # Test the problematic NMS operator that was causing circular imports\n",
    "    import torch\n",
    "    boxes = torch.tensor([[0, 0, 1, 1], [0.5, 0.5, 1.5, 1.5]], dtype=torch.float32)\n",
    "    scores = torch.tensor([0.9, 0.8], dtype=torch.float32)\n",
    "    keep = tv_module.ops.nms(boxes, scores, 0.5)\n",
    "    print(\"   🧪 NMS operator test: PASSED\")\n",
    "\n",
    "success, torchvision = safe_import_test(\"torchvision\", test_torchvision)\n",
    "all_good &= success\n",
    "\n",
    "# Test Transformers with the specific function that was failing\n",
    "def test_transformers(tf_module):\n",
    "    from transformers.utils import is_quanto_available\n",
    "    print(\"   🔧 is_quanto_available function: FOUND\")\n",
    "\n",
    "success, transformers = safe_import_test(\"transformers\", test_transformers)\n",
    "all_good &= success\n",
    "\n",
    "# Test other critical dependencies\n",
    "for module in [\"numpy\", \"gradio\", \"soundfile\", \"librosa\"]:\n",
    "    success, _ = safe_import_test(module)\n",
    "    all_good &= success\n",
    "\n",
    "# Test ChatterBox TTS\n",
    "def test_chatterbox(cb_module):\n",
    "    # Just test that we can access the main class\n",
    "    tts_class = getattr(cb_module.tts, 'ChatterboxTTS')\n",
    "    print(\"   🎤 ChatterboxTTS class: ACCESSIBLE\")\n",
    "\n",
    "success, chatterbox = safe_import_test(\"chatterbox\", test_chatterbox)\n",
    "all_good &= success\n",
    "\n",
    "print(\"=\" * 60)\n",
    "if all_good:\n",
    "    print(\"🎉 ALL TESTS PASSED! No circular import issues detected.\")\n",
    "    print(\"🚀 You can proceed to Step 3.\")\n",
    "else:\n",
    "    print(\"⚠️ Some tests failed. Recommended actions:\")\n",
    "    print(\"1. 🔄 Runtime → Restart Runtime\")\n",
    "    print(\"2. 🔄 Re-run Step 1\")\n",
    "    print(\"3. 📧 If issues persist, check your Colab runtime type (should be GPU)\")\n",
    "\n",
    "print(f\"\\n📊 Python version: {sys.version}\")\n",
    "print(f\"🔍 Total modules loaded: {len(sys.modules)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download_header"
   },
   "source": [
    "## 📥 Step 3: Download Repository\n",
    "\n",
    "Clone the ChatterBox Unlimited repository with the Gradio interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_repo"
   },
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/Wamp1re-Ai/Chatterbox-Unlimited-Colab.git\n",
    "%cd Chatterbox-Unlimited-Colab\n",
    "\n",
    "# List files\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "launch_header"
   },
   "source": [
    "## 🚀 Step 4: Launch ChatterBox TTS Interface\n",
    "\n",
    "This will start the Gradio web interface. The model will automatically download (~5GB) on first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "launch_interface"
   },
   "outputs": [],
   "source": [
    "# Launch the ChatterBox TTS interface\n",
    "!python main.py --share --port 7860\n",
    "\n",
    "# Note: The interface will be available at the Gradio public link\n",
    "# Look for the line that says \"Running on public URL: https://xxxxx.gradio.live\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usage_instructions"
   },
   "source": [
    "## 🎯 How to Use\n",
    "\n",
    "Once the interface is running:\n",
    "\n",
    "### Basic Text-to-Speech\n",
    "1. **Load Model**: Click \"Load ChatterBox TTS Model\" (first time may take a few minutes)\n",
    "2. **Enter Text**: Type your text in the input box\n",
    "3. **Adjust Settings**:\n",
    "   - **Exaggeration**: 0.0-1.0 (emotion intensity)\n",
    "   - **CFG Weight**: 0.0-1.0 (speech pacing)\n",
    "4. **Generate**: Click \"🎤 Generate Speech\"\n",
    "\n",
    "### Voice Cloning\n",
    "1. **Upload Reference Audio**: 3-10 seconds of clear speech\n",
    "2. **Enter Text**: What you want the cloned voice to say\n",
    "3. **Generate**: The output will mimic the reference voice\n",
    "\n",
    "### Tips for Best Results\n",
    "- **General Use**: Default settings (0.5, 0.5) work well\n",
    "- **Expressive Speech**: Lower CFG (~0.3) + higher exaggeration (~0.7+)\n",
    "- **Voice Cloning**: Use clear, high-quality reference audio\n",
    "- **GPU Acceleration**: Colab's GPU will make generation much faster!\n",
    "\n",
    "---\n",
    "\n",
    "## 📝 Notes\n",
    "- Generated audio includes watermarking for responsible AI use\n",
    "- First model load downloads ~5GB of weights\n",
    "- Colab session will timeout after inactivity\n",
    "- For extended use, consider Colab Pro for longer sessions\n",
    "\n",
    "## 🔧 Troubleshooting\n",
    "\n",
    "### Fixed Issues in This Version\n",
    "\n",
    "**✅ FIXED: `partially initialized module 'torchvision' has no attribute 'extension'`**\n",
    "- **Root Cause**: Circular import between PyTorch and TorchVision\n",
    "- **Solution**: Complete cleanup + sequential installation + import cache clearing\n",
    "- **Prevention**: Uses compatible PyTorch 2.1.0 + TorchVision 0.16.0\n",
    "\n",
    "**✅ FIXED: `cannot import name 'is_quanto_available' from 'transformers.utils'`**\n",
    "- **Root Cause**: Outdated transformers version\n",
    "- **Solution**: Updated to transformers>=4.46.0\n",
    "\n",
    "### Remaining Troubleshooting\n",
    "\n",
    "**❌ ChatterBox TTS import fails**\n",
    "- **Solution**: The notebook tries both PyPI and GitHub installation\n",
    "- **Manual fix**: `!pip install git+https://github.com/resemble-ai/chatterbox.git`\n",
    "\n",
    "**⚠️ Slow generation**\n",
    "- **Check**: Make sure GPU is enabled (Runtime → Change runtime type → GPU)\n",
    "- **Verify**: Step 2 should show your GPU name\n",
    "\n",
    "**🔄 General troubleshooting steps:**\n",
    "1. Restart runtime: Runtime → Restart Runtime\n",
    "2. Re-run all cells from Step 1\n",
    "3. If Step 2 shows issues, repeat steps 1-2\n",
    "4. Check that GPU is enabled in runtime settings\n",
    "\n",
    "## 🔗 Links\n",
    "- [GitHub Repository](https://github.com/Wamp1re-Ai/Chatterbox-Unlimited-Colab)\n",
    "- [ResembleAI ChatterBox](https://github.com/resemble-ai/chatterbox)\n",
    "- [Hugging Face Model](https://huggingface.co/ResembleAI/chatterbox)\n",
    "\n",
    "**Enjoy creating amazing speech with ChatterBox Unlimited! 🎉**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
