{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üé§ ChatterBox TTS - Simple & Reliable Colab Edition\n",
    "\n",
    "**A streamlined approach to running ResembleAI's ChatterBox TTS in Google Colab**\n",
    "\n",
    "## ‚ú® Features\n",
    "- üéØ **Zero-shot TTS**: Generate speech from any text\n",
    "- üé≠ **Voice Cloning**: Clone voices from audio samples\n",
    "- üé® **Emotion Control**: Adjust expressiveness and intensity\n",
    "- üöÄ **GPU Acceleration**: Fast generation with Colab's GPUs\n",
    "- üåê **Web Interface**: Beautiful Gradio UI\n",
    "- üîß **Simplified Setup**: Works with Colab's existing environment\n",
    "\n",
    "## üöÄ Quick Start\n",
    "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí GPU\n",
    "2. **Run all cells** below in order\n",
    "3. **Access the interface** through the Gradio link\n",
    "4. **Start generating speech**!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_header"
   },
   "source": [
    "## üì¶ Step 1: Environment Setup & Dependencies\n",
    "\n",
    "This approach works with Colab's existing PyTorch installation for maximum compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_environment"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import importlib\n",
    "\n",
    "print(\"üîç Checking Colab environment...\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Check if we're in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"‚úÖ Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"‚ö†Ô∏è Not running in Colab - some features may not work\")\n",
    "\n",
    "# Check existing PyTorch installation\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"‚úÖ PyTorch {torch.__version__} already installed\")\n",
    "    print(f\"üéÆ CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"üì± GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå PyTorch not found - installing...\")\n",
    "    !pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "print(\"\\nüîß Installing core dependencies...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "# Install essential packages that work well with Colab\n",
    "packages_to_install = [\n",
    "    \"gradio>=4.0.0\",\n",
    "    \"soundfile\",\n",
    "    \"librosa\",\n",
    "    \"numpy>=1.24.0\",\n",
    "    \"transformers>=4.40.0\",\n",
    "    \"accelerate\",\n",
    "    \"safetensors\",\n",
    "    \"omegaconf\",\n",
    "    \"einops\"\n",
    "]\n",
    "\n",
    "print(\"üì¶ Installing compatible packages...\")\n",
    "for package in packages_to_install:\n",
    "    try:\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", package], \n",
    "                      check=True, capture_output=True, text=True)\n",
    "        print(f\"‚úÖ {package}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ö†Ô∏è {package} - {e.stderr.strip()[:100]}...\")\n",
    "\n",
    "print(\"\\nüé§ Installing ChatterBox TTS...\")\n",
    "# Try multiple installation methods for ChatterBox TTS\n",
    "chatterbox_installed = False\n",
    "\n",
    "# Method 1: Try PyPI first\n",
    "try:\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"chatterbox-tts\"], \n",
    "                  check=True, capture_output=True, text=True)\n",
    "    print(\"‚úÖ ChatterBox TTS installed from PyPI\")\n",
    "    chatterbox_installed = True\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"‚ö†Ô∏è PyPI installation failed, trying GitHub...\")\n",
    "\n",
    "# Method 2: Try GitHub if PyPI fails\n",
    "if not chatterbox_installed:\n",
    "    try:\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \n",
    "                       \"git+https://github.com/resemble-ai/chatterbox.git\"], \n",
    "                      check=True, capture_output=True, text=True)\n",
    "        print(\"‚úÖ ChatterBox TTS installed from GitHub\")\n",
    "        chatterbox_installed = True\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"‚ùå GitHub installation also failed\")\n",
    "\n",
    "# Method 3: Manual installation if both fail\n",
    "if not chatterbox_installed:\n",
    "    print(\"üîß Attempting manual installation...\")\n",
    "    !git clone https://github.com/resemble-ai/chatterbox.git /tmp/chatterbox\n",
    "    !cd /tmp/chatterbox && pip install -e .\n",
    "    chatterbox_installed = True\n",
    "\n",
    "print(\"\\nüéâ Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test_header"
   },
   "source": [
    "## üß™ Step 2: Test Installation & Compatibility\n",
    "\n",
    "Let's verify everything is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_installation"
   },
   "outputs": [],
   "source": [
    "def test_import(module_name, friendly_name=None):\n",
    "    \"\"\"Test if a module can be imported successfully\"\"\"\n",
    "    if friendly_name is None:\n",
    "        friendly_name = module_name\n",
    "    \n",
    "    try:\n",
    "        module = importlib.import_module(module_name)\n",
    "        version = getattr(module, '__version__', 'unknown')\n",
    "        print(f\"‚úÖ {friendly_name}: {version}\")\n",
    "        return True, module\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {friendly_name}: {str(e)[:100]}...\")\n",
    "        return False, None\n",
    "\n",
    "print(\"üîç Testing all imports...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test core dependencies\n",
    "success_count = 0\n",
    "total_tests = 0\n",
    "\n",
    "modules_to_test = [\n",
    "    (\"torch\", \"PyTorch\"),\n",
    "    (\"torchaudio\", \"TorchAudio\"),\n",
    "    (\"transformers\", \"Transformers\"),\n",
    "    (\"gradio\", \"Gradio\"),\n",
    "    (\"soundfile\", \"SoundFile\"),\n",
    "    (\"librosa\", \"Librosa\"),\n",
    "    (\"numpy\", \"NumPy\")\n",
    "]\n",
    "\n",
    "for module_name, friendly_name in modules_to_test:\n",
    "    success, _ = test_import(module_name, friendly_name)\n",
    "    if success:\n",
    "        success_count += 1\n",
    "    total_tests += 1\n",
    "\n",
    "# Test ChatterBox TTS specifically\n",
    "print(\"\\nüé§ Testing ChatterBox TTS...\")\n",
    "try:\n",
    "    from chatterbox.tts import ChatterboxTTS\n",
    "    print(\"‚úÖ ChatterBox TTS: Import successful\")\n",
    "    success_count += 1\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ChatterBox TTS: {str(e)[:100]}...\")\n",
    "total_tests += 1\n",
    "\n",
    "# Test GPU availability\n",
    "print(\"\\nüéÆ GPU Status:\")\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"‚úÖ CUDA available: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "        print(f\"üîß CUDA Version: {torch.version.cuda}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è CUDA not available - will use CPU (slower)\")\n",
    "except:\n",
    "    print(\"‚ùå Could not check GPU status\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"üìä Test Results: {success_count}/{total_tests} passed\")\n",
    "\n",
    "if success_count == total_tests:\n",
    "    print(\"üéâ All tests passed! Ready to proceed.\")\n",
    "elif success_count >= total_tests - 1:\n",
    "    print(\"‚úÖ Most tests passed. Should work with minor issues.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Some tests failed. May encounter issues.\")\n",
    "    print(\"üí° Try restarting runtime and running again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "interface_header"
   },
   "source": [
    "## üöÄ Step 3: Launch ChatterBox TTS Interface\n",
    "\n",
    "Create and launch the Gradio web interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_interface"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Global variables for model\n",
    "model = None\n",
    "model_loaded = False\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Load the ChatterBox TTS model\"\"\"\n",
    "    global model, model_loaded\n",
    "    \n",
    "    if model_loaded:\n",
    "        return \"‚úÖ Model already loaded!\"\n",
    "    \n",
    "    try:\n",
    "        print(\"üîÑ Loading ChatterBox TTS model...\")\n",
    "        from chatterbox.tts import ChatterboxTTS\n",
    "        \n",
    "        # Determine device\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"üéÆ Using device: {device}\")\n",
    "        \n",
    "        # Load model\n",
    "        model = ChatterboxTTS.from_pretrained(device=device)\n",
    "        model_loaded = True\n",
    "        \n",
    "        return f\"‚úÖ Model loaded successfully on {device}!\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"‚ùå Failed to load model: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "\n",
    "def generate_speech(text, audio_file=None, exaggeration=0.5, cfg_weight=0.5):\n",
    "    \"\"\"Generate speech from text with optional voice cloning\"\"\"\n",
    "    global model, model_loaded\n",
    "    \n",
    "    if not model_loaded or model is None:\n",
    "        return None, \"‚ùå Please load the model first!\"\n",
    "    \n",
    "    if not text.strip():\n",
    "        return None, \"‚ùå Please enter some text to synthesize!\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"üé§ Generating speech for: '{text[:50]}...'\")\n",
    "        \n",
    "        # Generate speech\n",
    "        if audio_file is not None:\n",
    "            # Voice cloning mode\n",
    "            print(\"üé≠ Using voice cloning mode\")\n",
    "            wav = model.generate(\n",
    "                text, \n",
    "                audio_prompt_path=audio_file,\n",
    "                exaggeration=exaggeration,\n",
    "                cfg_weight=cfg_weight\n",
    "            )\n",
    "        else:\n",
    "            # Standard TTS mode\n",
    "            print(\"üéØ Using standard TTS mode\")\n",
    "            wav = model.generate(\n",
    "                text,\n",
    "                exaggeration=exaggeration,\n",
    "                cfg_weight=cfg_weight\n",
    "            )\n",
    "        \n",
    "        # Save to temporary file\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp_file:\n",
    "            torchaudio.save(tmp_file.name, wav, model.sr)\n",
    "            \n",
    "        success_msg = f\"‚úÖ Generated {wav.shape[1]/model.sr:.1f}s of audio\"\n",
    "        print(success_msg)\n",
    "        \n",
    "        return tmp_file.name, success_msg\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"‚ùå Generation failed: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return None, error_msg\n",
    "\n",
    "print(\"üé® Creating Gradio interface...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "launch_interface"
   },
   "outputs": [],
   "source": [
    "# Create the Gradio interface\n",
    "with gr.Blocks(title=\"ChatterBox TTS - Simple Colab Edition\", theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # üé§ ChatterBox TTS - Simple & Reliable\n",
    "    \n",
    "    **State-of-the-art Text-to-Speech and Voice Cloning**\n",
    "    \n",
    "    Generate natural-sounding speech from text, or clone voices from audio samples!\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            # Model loading section\n",
    "            gr.Markdown(\"### üîß Model Setup\")\n",
    "            load_btn = gr.Button(\"üöÄ Load ChatterBox TTS Model\", variant=\"primary\", size=\"lg\")\n",
    "            load_status = gr.Textbox(label=\"Status\", interactive=False, value=\"Click to load model...\")\n",
    "            \n",
    "            # Text input\n",
    "            gr.Markdown(\"### üìù Text Input\")\n",
    "            text_input = gr.Textbox(\n",
    "                label=\"Text to synthesize\",\n",
    "                placeholder=\"Enter the text you want to convert to speech...\",\n",
    "                lines=3,\n",
    "                value=\"Hello! This is ChatterBox TTS, a state-of-the-art text-to-speech model. I can generate natural-sounding speech from any text you provide.\"\n",
    "            )\n",
    "            \n",
    "            # Voice cloning section\n",
    "            gr.Markdown(\"### üé≠ Voice Cloning (Optional)\")\n",
    "            audio_input = gr.Audio(\n",
    "                label=\"Reference audio for voice cloning\",\n",
    "                type=\"filepath\",\n",
    "                sources=[\"upload\", \"microphone\"]\n",
    "            )\n",
    "            gr.Markdown(\"*Upload 3-10 seconds of clear speech to clone a voice*\")\n",
    "            \n",
    "            # Advanced settings\n",
    "            with gr.Accordion(\"‚öôÔ∏è Advanced Settings\", open=False):\n",
    "                exaggeration = gr.Slider(\n",
    "                    minimum=0.0,\n",
    "                    maximum=1.0,\n",
    "                    value=0.5,\n",
    "                    step=0.1,\n",
    "                    label=\"Exaggeration (emotion intensity)\",\n",
    "                    info=\"Higher values = more expressive speech\"\n",
    "                )\n",
    "                cfg_weight = gr.Slider(\n",
    "                    minimum=0.0,\n",
    "                    maximum=1.0,\n",
    "                    value=0.5,\n",
    "                    step=0.1,\n",
    "                    label=\"CFG Weight (speech pacing)\",\n",
    "                    info=\"Lower values = slower, more deliberate speech\"\n",
    "                )\n",
    "        \n",
    "        with gr.Column():\n",
    "            # Generation section\n",
    "            gr.Markdown(\"### üéµ Generated Audio\")\n",
    "            generate_btn = gr.Button(\"üé§ Generate Speech\", variant=\"primary\", size=\"lg\")\n",
    "            generation_status = gr.Textbox(label=\"Generation Status\", interactive=False)\n",
    "            \n",
    "            audio_output = gr.Audio(\n",
    "                label=\"Generated Speech\",\n",
    "                type=\"filepath\",\n",
    "                interactive=False\n",
    "            )\n",
    "            \n",
    "            # Tips section\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### üí° Tips for Best Results\n",
    "            \n",
    "            **General Use:**\n",
    "            - Default settings (0.5, 0.5) work well for most text\n",
    "            - For fast speakers, try lowering CFG weight to ~0.3\n",
    "            \n",
    "            **Expressive Speech:**\n",
    "            - Lower CFG weight (~0.3) + higher exaggeration (~0.7+)\n",
    "            - Higher exaggeration speeds up speech; lower CFG compensates\n",
    "            \n",
    "            **Voice Cloning:**\n",
    "            - Use 3-10 seconds of clear, high-quality audio\n",
    "            - Single speaker, minimal background noise\n",
    "            - The model will mimic the reference voice's characteristics\n",
    "            \"\"\")\n",
    "    \n",
    "    # Event handlers\n",
    "    load_btn.click(\n",
    "        fn=load_model,\n",
    "        outputs=load_status\n",
    "    )\n",
    "    \n",
    "    generate_btn.click(\n",
    "        fn=generate_speech,\n",
    "        inputs=[text_input, audio_input, exaggeration, cfg_weight],\n",
    "        outputs=[audio_output, generation_status]\n",
    "    )\n",
    "\n",
    "# Launch the interface\n",
    "print(\"üöÄ Launching Gradio interface...\")\n",
    "demo.launch(\n",
    "    share=True,\n",
    "    debug=True,\n",
    "    show_error=True,\n",
    "    server_port=7860\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usage_guide"
   },
   "source": [
    "## üìñ Usage Guide\n",
    "\n",
    "### üöÄ Getting Started\n",
    "1. **Load Model**: Click \"üöÄ Load ChatterBox TTS Model\" (first time takes ~2-3 minutes)\n",
    "2. **Enter Text**: Type your text in the input box\n",
    "3. **Generate**: Click \"üé§ Generate Speech\"\n",
    "4. **Download**: Right-click the audio player to save your generated speech\n",
    "\n",
    "### üé≠ Voice Cloning\n",
    "1. **Upload Reference**: Use a 3-10 second audio clip of the target voice\n",
    "2. **Quality Matters**: Clear speech, minimal background noise\n",
    "3. **Generate**: The output will mimic the reference voice characteristics\n",
    "\n",
    "### ‚öôÔ∏è Parameter Guide\n",
    "- **Exaggeration (0.0-1.0)**: Controls emotion intensity and expressiveness\n",
    "  - `0.0-0.3`: Calm, neutral speech\n",
    "  - `0.4-0.6`: Natural expressiveness (recommended)\n",
    "  - `0.7-1.0`: Highly expressive, dramatic speech\n",
    "\n",
    "- **CFG Weight (0.0-1.0)**: Controls speech pacing and adherence to text\n",
    "  - `0.0-0.3`: Slower, more deliberate speech\n",
    "  - `0.4-0.6`: Natural pacing (recommended)\n",
    "  - `0.7-1.0`: Faster, more direct speech\n",
    "\n",
    "### üéØ Optimization Tips\n",
    "- **For Podcasts/Narration**: `exaggeration=0.4, cfg_weight=0.5`\n",
    "- **For Character Voices**: `exaggeration=0.7, cfg_weight=0.3`\n",
    "- **For News/Professional**: `exaggeration=0.3, cfg_weight=0.6`\n",
    "- **For Audiobooks**: `exaggeration=0.5, cfg_weight=0.4`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "troubleshooting"
   },
   "source": [
    "## üîß Troubleshooting\n",
    "\n",
    "### ‚ùå Common Issues & Solutions\n",
    "\n",
    "**\"Model failed to load\"**\n",
    "- ‚úÖ Restart runtime: Runtime ‚Üí Restart Runtime\n",
    "- ‚úÖ Re-run all cells from Step 1\n",
    "- ‚úÖ Check GPU is enabled: Runtime ‚Üí Change runtime type ‚Üí GPU\n",
    "\n",
    "**\"Generation failed\"**\n",
    "- ‚úÖ Make sure model is loaded first\n",
    "- ‚úÖ Check text input is not empty\n",
    "- ‚úÖ Try shorter text (< 200 characters)\n",
    "- ‚úÖ Restart runtime if memory issues occur\n",
    "\n",
    "**\"Slow generation\"**\n",
    "- ‚úÖ Ensure GPU is enabled and detected\n",
    "- ‚úÖ Check Step 2 shows CUDA available\n",
    "- ‚úÖ Close other browser tabs to free memory\n",
    "\n",
    "**\"Voice cloning not working\"**\n",
    "- ‚úÖ Use 3-10 second audio clips\n",
    "- ‚úÖ Ensure clear speech, single speaker\n",
    "- ‚úÖ Try WAV format for best results\n",
    "- ‚úÖ Check audio file uploaded successfully\n",
    "\n",
    "### üÜò Emergency Reset\n",
    "If nothing works:\n",
    "1. Runtime ‚Üí Restart Runtime\n",
    "2. Edit ‚Üí Clear all outputs\n",
    "3. Run all cells again from the beginning\n",
    "\n",
    "### üìä Performance Notes\n",
    "- **First load**: ~2-3 minutes (downloads ~500MB model)\n",
    "- **Generation time**: 5-15 seconds per sentence (GPU)\n",
    "- **Memory usage**: ~2-3GB GPU memory\n",
    "- **Audio quality**: 22kHz, watermarked for responsible AI use\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Resources\n",
    "\n",
    "- **Original Model**: [ResembleAI ChatterBox](https://github.com/resemble-ai/chatterbox)\n",
    "- **Demo Page**: [Official Samples](https://resemble-ai.github.io/chatterbox_demopage/)\n",
    "- **Hugging Face**: [Model Card](https://huggingface.co/ResembleAI/chatterbox)\n",
    "- **Discord**: [Join Community](https://discord.gg/rJq9cRJBJ6)\n",
    "\n",
    "**Built with ‚ù§Ô∏è for the open-source community**\n",
    "\n",
    "*This notebook uses a simplified approach that works with Colab's existing environment for maximum reliability.*"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
